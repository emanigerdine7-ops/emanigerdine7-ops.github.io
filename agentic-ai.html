<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Agency Paradox: Agentic AI - The Agency Paradox</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>The Agency Paradox</h1>
        <nav>
            <a href="index.html">Home</a>
            <a href="about.html">About</a>
        </nav>
    </header>

    <main>
        <article>
            <h2>The Agency Paradox: When AI Starts Acting for Itself</h2>
            <p class="date">January 23, 2026</p>

            <p>In my exploration of "The Agency Paradox," I've been thinking about the line between tools we control and tools that act on their own. A recent article from <a href="https://www.teksystems.com/en/insights/version-next-now/2025/agentic-ai">TEKsystems</a> perfectly captures this tension as we move into the era of <strong>Agentic AI.</strong></p>

            <p>The paradox is simple: As we give AI more "agency" to solve our problems, we actually have to become more vigilant in how we monitor it.</p>

            <h3>From Assistance to Autonomy</h3>
            <p>We are moving away from tools that just answer questions toward "doers" that can interpret context and execute workflows. These agents can collaborate with each other to solve complex problems, potentially automating up to 70% of office tasks in the next decade.</p>

            <h3>The Supervision Gap</h3>
            <p>One of the biggest points in the article is that Agentic AI is not "set-it-and-forget-it." Because these tools can interact with databases and move data, the risk of error is higher. This is the heart of my blog's theme: to gain the freedom of automation, we must invest more in oversight.</p>

            <p><strong>What do you think? Are we ready for AI that takes the next step for us?</strong></p>
        </article>
    </main>

    <footer>
        <p>&copy; 2026 Emani Gerdine - ENGL 170</p>
    </footer>
</body>
</html>
